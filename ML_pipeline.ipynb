{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress warnings. Comment out if required.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ML libraries\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "# Python lightweight pipelining\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(pipeline, X, y):\n",
    "    y_predict_proba = pipeline.predict_proba(X)[:, 1]\n",
    "    return{\n",
    "        'auc': roc_auc_score(y, y_predict_proba)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['feat_1', 'feat_2', 'feat_3', 'feat_4']\n",
    "categorical_features = ['feat_5', 'feat_6', 'feat_7', 'feat_8']\n",
    "\n",
    "# Generate a dataset with 4 classes using 10k samples\n",
    "# Target variable y has approximately 50% 0 and 50% 1\n",
    "X, y = make_classification(n_samples=10000, \n",
    "                           n_features=4, \n",
    "                           n_redundant=0, \n",
    "                           random_state=42, \n",
    "                           weights=[0.5])\n",
    "\n",
    "# For each categorical column: \n",
    "#   1. a random between 2 and 10 is chosen (this is variable num_classes)\n",
    "#   2. the entire categorical column is filled with random numbers between 0 and (num_classes -1)\n",
    "#   3. reshape the output to be a single column of 10000 numbers\n",
    "#   4. horizontally append the column to X\n",
    "for col in range(4):\n",
    "    num_classes = np.random.randint(2, 10)\n",
    "    # Numpy reshape(-1, 1)\n",
    "    #   number of rows = -1 (unknown, Numpy figures it out)\n",
    "    #   number of columns = 1\n",
    "    cat_col = np.random.randint(num_classes, size=X.shape[0]).reshape(-1,1)\n",
    "    X = np.hstack((X, cat_col))\n",
    "\n",
    "# To DataFrame\n",
    "columns = [f'feat_{i+1}' for i in range(X.shape[1])]\n",
    "X = pd.DataFrame(X, columns=columns)\n",
    "y = pd.DataFrame(y, columns=['label'])\n",
    "\n",
    "# Make_classification gives us a normally distributed dataset\n",
    "# Code shifts the mean and standard deviation to make it more realistic\n",
    "for col in numerical_features:\n",
    "    mean = np.random.randint(10, 1000)\n",
    "    std = np.random.randint(1, 100)\n",
    "    X[col] = X[col].apply(lambda x: mean + std * x).astype(int)\n",
    "\n",
    "# Categories converted to string values to force pre-processing later\n",
    "for col in categorical_features:\n",
    "    X[col] = X[col].apply(lambda x: f'str_{x}' if np.isnan(x)==False else x)\n",
    "\n",
    "# Introduce Nans into the dataset\n",
    "# frac=0.7 means that 70% are not Nan\n",
    "for col in categorical_features + numerical_features:\n",
    "    X[col] = X[col].sample(frac=0.7)\n",
    "\n",
    "# Created final DataFrame\n",
    "df = X.merge(y,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"feat_5: {df['feat_5'].unique()}\")\n",
    "print(f\"feat_6: {df['feat_6'].unique()}\")\n",
    "print(f\"feat_7: {df['feat_7'].unique()}\")\n",
    "print(f\"feat_8: {df['feat_8'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns 1 to 4: mean (between 10 and 1000) + standard deviation (between 1 to 100) * x (float 0 to 1)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "X_train, y_train = train_df[categorical_features + numerical_features], train_df['label']\n",
    "X_test, y_test = test_df[categorical_features + numerical_features], test_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline using CatBoost model\n",
    "\n",
    "\n",
    "### Categorical features\n",
    "\n",
    "* Variable 'cat'\n",
    "* SimpleImputer replaces all Nans with string value 'UNK'\n",
    "* OrdinalEncoder encodes the categories as 0 .. N where N is the number of classes\n",
    "  * It also handles new classes that were not in the original training set \n",
    "  * Assigns new classes as -1\n",
    "  * Useful feature when model is used in production\n",
    "\n",
    "\n",
    "### Numerical features\n",
    "\n",
    "* Variable 'num'\n",
    "* SimpleImputer replaces Nans with the mean of the column\n",
    "\n",
    "\n",
    "### DataFrameMapper\n",
    "\n",
    "* Groups together data transformations\n",
    "* Here, we apply the transformations on the categorical 'cat' and numerical 'num' features\n",
    "* Default output of the mapper is a Numpy array. Setting df_out=True changes the output to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = [([c], [SimpleImputer(strategy='constant', fill_value='UNK'),\n",
    "              OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)]) for c in categorical_features]\n",
    "              \n",
    "num = [([n], [SimpleImputer()]) for n in numerical_features]\n",
    "mapper = DataFrameMapper(num + cat, df_out=True)\n",
    "clf = CatBoostClassifier(iterations=1000,\n",
    "                         learning_rate=0.01,\n",
    "                         metric_period=100)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_X_test = mapper.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test shows the data BEFORE transformations\n",
    "X_test[numerical_features + categorical_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_X_test shows the data AFTER transformations\n",
    "#   Nans in each numerical column are imputed with the mean of the column\n",
    "#   Values in the each categorical column are ordinal encoded\n",
    "preprocessed_X_test[numerical_features + categorical_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Python joblib.dump to persist the pipeline object to file\n",
    "dump(pipeline, 'params/pipeline.joblib')\n",
    "\n",
    "# Also save the test dataset to file\n",
    "test_df.to_csv('params/test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train AUC score = 0.932\n",
    "evaluation(pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test AUC score = 0.915\n",
    "evaluation(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline using Logistic Regression model\n",
    "\n",
    "### Categorical features\n",
    "\n",
    "* Variable 'cat'\n",
    "* SimpleImputer replaces all Nans with string value 'UNK'\n",
    "* Replace OrdinalEncoder with OneHotEncoder\n",
    "  * One hot encoding works well with Logistic regression\n",
    "\n",
    "\n",
    "### Numerical features\n",
    "\n",
    "* Variable 'num'\n",
    "* SimpleImputer replaces Nans with the mean of the column\n",
    "* StandardScaler scales our features to be between 0 and 1\n",
    "\n",
    "\n",
    "### DataFrameMapper\n",
    "\n",
    "* Groups together data transformations\n",
    "* Here, we apply the transformations on the categorical 'cat' and numerical 'num' features\n",
    "* Default output of the mapper is a Numpy array. Setting df_out=True changes the output to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = [([c], [SimpleImputer(strategy='constant', fill_value='UNK'),\n",
    "              OneHotEncoder()]) for c in categorical_features]\n",
    "num = [([n], [SimpleImputer(), StandardScaler()]) for n in numerical_features]\n",
    "mapper = DataFrameMapper(num + cat, df_out=True)\n",
    "clf = LogisticRegression()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', mapper),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_X_test = mapper.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test shows the data BEFORE transformations\n",
    "X_test[numerical_features + categorical_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_X_test shows the data AFTER transformations\n",
    "#   Nans in each numerical column are imputed with the mean of the column\n",
    "#   Values in the each categorical column are one-hot encoded\n",
    "preprocessed_X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train AUC score = 0.878\n",
    "evaluation(pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test AUC score = 0.878\n",
    "evaluation(pipeline, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e62e41617f0e8a6e31cb2897d2b20e34bc661183d6c13dc1da307e94ce7df895"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38_ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
